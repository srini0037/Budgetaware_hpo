"""
Budget-Aware Comparison Experiment
==================================

Tests all three HPO methods (Random Search, SHA, Hyperband) at different
budget levels to identify crossing points and efficiency trade-offs.

Budget levels: 60s, 120s, 300s, 600s
Runs: 5 per method per budget (for speed)

Estimated runtime: 2-3 hours
"""

import numpy as np
import pandas as pd
import time
import json
from pathlib import Path
from datetime import datetime
from scipy.stats import loguniform, randint

from sklearn.datasets import fetch_openml
from sklearn.utils import resample
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import f1_score

import warnings
warnings.filterwarnings('ignore')

import sys
sys.path.append('/Users/srinivass/Budgetaware_hpo')
from hpo.hyperband_implementation import Hyperband, get_random_mlp_config


print("=" * 80)
print("BUDGET-AWARE HPO COMPARISON EXPERIMENT")
print("=" * 80)
print(f"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 80)


# ============================================================================
# CONFIGURATION
# ============================================================================

BUDGET_LEVELS = {
    'very_low': 60,    # 1 minute
    'low': 120,        # 2 minutes
    'medium': 300,     # 5 minutes
    'high': 600,       # 10 minutes
}

N_RUNS = 10  # 10 runs for proper statistical validation
SEEDS = list(range(N_RUNS))


# ============================================================================
# LOAD DATA
# ============================================================================

print("\nðŸ“Š Loading Covertype dataset...")

X, y = fetch_openml(name="covertype", version=2, as_frame=False, return_X_y=True)

if hasattr(X, 'toarray'):
    X = X.toarray()

y = y.astype(int)

MAX_SAMPLES = 50000
if X.shape[0] > MAX_SAMPLES:
    X, y = resample(X, y, n_samples=MAX_SAMPLES, stratify=y, random_state=42)

print(f"âœ… Dataset: {X.shape}, Classes: {len(np.unique(y))}")

X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)

print(f"âœ… Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}")


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def evaluate_config(config, X_train, y_train):
    """Evaluate a single configuration using 3-fold CV"""
    model = Pipeline([
        ('scaler', StandardScaler()),
        ('mlp', MLPClassifier(**config, random_state=42))
    ])
    
    scores = cross_val_score(
        model, X_train, y_train,
        cv=3, scoring='f1_macro', n_jobs=1
    )
    
    return scores.mean()


def run_random_search_with_budget(X_train, y_train, time_budget, seed=42):
    """Run Random Search until budget is exhausted"""
    np.random.seed(seed)
    
    start_time = time.time()
    best_score = 0
    best_config = None
    configs_evaluated = 0
    
    while True:
        elapsed = time.time() - start_time
        if elapsed >= time_budget:
            break
        
        config = get_random_mlp_config()
        score = evaluate_config(config, X_train, y_train)
        
        if score > best_score:
            best_score = score
            best_config = config
        
        configs_evaluated += 1
        
        # Don't start new if budget almost exhausted
        if time.time() - start_time > time_budget * 0.95:
            break
    
    total_time = time.time() - start_time
    
    return {
        'best_score': best_score,
        'configs_evaluated': configs_evaluated,
        'time_used': total_time,
        'budget_exhausted': total_time >= time_budget * 0.95
    }


def run_sha_with_budget(X_train, y_train, time_budget, seed=42):
    """Run SHA, stopping when budget is exhausted"""
    np.random.seed(seed)
    
    start_time = time.time()
    
    # Start with smaller n_configs for budget awareness
    n_configs = 27
    max_iter = 81
    eta = 3
    
    configs = [get_random_mlp_config() for _ in range(n_configs)]
    s = int(np.floor(np.log(n_configs) / np.log(eta)))
    r = max_iter / (eta ** s)
    
    configs_evaluated = 0
    best_score = 0
    best_config = None
    
    for i in range(s + 1):
        # Check budget
        if time.time() - start_time >= time_budget:
            break
        
        n_i = int(n_configs / (eta ** i))
        r_i = int(r * (eta ** i))
        
        scores = []
        for config in configs:
            # Check budget before each evaluation
            if time.time() - start_time >= time_budget:
                break
            
            config_copy = config.copy()
            config_copy['max_iter'] = r_i
            score = evaluate_config(config_copy, X_train, y_train)
            scores.append(score)
            configs_evaluated += 1
            
            if score > best_score:
                best_score = score
                best_config = config_copy
        
        if i < s and len(scores) > 0:
            n_keep = max(1, int(n_i / eta))
            if len(scores) >= n_keep:
                indices = np.argsort(scores)[-n_keep:]
                configs = [configs[j] for j in indices]
                scores = [scores[j] for j in indices]
    
    total_time = time.time() - start_time
    
    return {
        'best_score': best_score,
        'configs_evaluated': configs_evaluated,
        'time_used': total_time,
        'budget_exhausted': total_time >= time_budget * 0.95
    }


def run_hyperband_with_budget(X_train, y_train, time_budget, seed=42):
    """Run Hyperband, stopping when budget is exhausted"""
    np.random.seed(seed)
    
    start_time = time.time()
    
    # Use smaller max_iter for budget awareness
    hb = Hyperband(
        get_random_config=get_random_mlp_config,
        max_iter=81,
        eta=3,
        verbose=False
    )
    
    # Monkey-patch to respect budget
    original_run = hb.run
    
    def budget_aware_run(X, y):
        # This is a simplified version - just runs normally
        # In practice, would need to check budget inside run()
        return original_run(X, y)
    
    hb.run = budget_aware_run
    
    # Check if we have enough time for at least one bracket
    if time_budget < 60:
        # Too short for Hyperband, return early
        return {
            'best_score': 0,
            'configs_evaluated': 0,
            'time_used': 0,
            'budget_exhausted': False
        }
    
    result = hb.run(X_train, y_train)
    total_time = time.time() - start_time
    
    # If over budget, mark as budget exhausted
    if total_time > time_budget:
        return {
            'best_score': result['best_score'],
            'configs_evaluated': result['configs_evaluated'],
            'time_used': total_time,
            'budget_exhausted': True
        }
    
    return {
        'best_score': result['best_score'],
        'configs_evaluated': result['configs_evaluated'],
        'time_used': total_time,
        'budget_exhausted': False
    }


# ============================================================================
# RUN EXPERIMENTS
# ============================================================================

results_dir = Path('/Users/srinivass/Budgetaware_hpo/results/hpo')
results_dir.mkdir(parents=True, exist_ok=True)

all_results = []
overall_start = time.time()

for budget_name, budget_seconds in BUDGET_LEVELS.items():
    print("\n" + "=" * 80)
    print(f"BUDGET LEVEL: {budget_name.upper()} ({budget_seconds}s)")
    print("=" * 80)
    
    for method_name in ['random_search', 'sha', 'hyperband']:
        print(f"\n{method_name.upper()}:")
        
        for run, seed in enumerate(SEEDS, 1):
            print(f"  Run {run}/{N_RUNS} (seed={seed})...", end=" ")
            
            if method_name == 'random_search':
                result = run_random_search_with_budget(X_train, y_train, budget_seconds, seed)
            elif method_name == 'sha':
                result = run_sha_with_budget(X_train, y_train, budget_seconds, seed)
            elif method_name == 'hyperband':
                result = run_hyperband_with_budget(X_train, y_train, budget_seconds, seed)
            
            all_results.append({
                'budget_level': budget_name,
                'budget_seconds': budget_seconds,
                'method': method_name,
                'run': run,
                'seed': seed,
                'best_score': result['best_score'],
                'configs_evaluated': result['configs_evaluated'],
                'time_used': result['time_used'],
                'budget_exhausted': result.get('budget_exhausted', False)
            })
            
            print(f"Score: {result['best_score']:.4f}, Configs: {result['configs_evaluated']}, Time: {result['time_used']:.1f}s")

# Save all results
results_df = pd.DataFrame(all_results)
results_df.to_csv(results_dir / 'budget_aware_comparison.csv', index=False)

print("\n" + "=" * 80)
print("âœ… ALL BUDGET EXPERIMENTS COMPLETE!")
print("=" * 80)

total_time = time.time() - overall_start
print(f"Total runtime: {total_time/60:.1f} minutes")
print(f"\nðŸ’¾ Results saved to: {results_dir / 'budget_aware_comparison.csv'}")

# Summary by budget and method
print("\nðŸ“Š SUMMARY BY BUDGET LEVEL:")
print("=" * 80)

summary = results_df.groupby(['budget_level', 'method'])['best_score'].agg(['mean', 'std', 'count'])
summary = summary.round(4)
print(summary)

print("\nðŸŽ‰ Ready for crossing point analysis!")
print("=" * 80)
